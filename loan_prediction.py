# -*- coding: utf-8 -*-
"""LOAN Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n8jdI1VX3xLtxE81uKVyprCnSPgyygJS
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix

!pip install openpyxl

import openpyxl

loan_df = pd.read_excel("/content/loan-predictionUC.csv (1) (1) (1) (3) (1) (2).xlsx")

# Display the first few rows of the dataset
print(loan_df.head())

# Get information about the dataset
print(loan_df.info())

# Summary statistics of numerical columns
print(loan_df.describe())

# Check for any missing values
print(loan_df.isnull().sum())

# Assuming you found missing values, you can either drop them or fill them with appropriate values
# For numerical columns, you can fill missing values with mean or median
loan_df['LoanAmount'].fillna(loan_df['LoanAmount'].median(), inplace=True)
loan_df['Loan_Amount_Term'].fillna(loan_df['Loan_Amount_Term'].mode()[0], inplace=True)

# For categorical columns, you can fill missing values with mode
loan_df['Gender'].fillna(loan_df['Gender'].mode()[0], inplace=True)
loan_df['Married'].fillna(loan_df['Married'].mode()[0], inplace=True)
loan_df['Dependents'].fillna(loan_df['Dependents'].mode()[0], inplace=True)
loan_df['Self_Employed'].fillna(loan_df['Self_Employed'].mode()[0], inplace=True)
loan_df['Credit_History'].fillna(loan_df['Credit_History'].mode()[0], inplace=True)
# Repeat this for other categorical columns with missing values

# Recheck if there are any missing values
print(loan_df.isnull().sum())

# Visualize the distribution of Loan_Status
sns.countplot(x='Loan_Status', data=loan_df)
plt.title('Loan Approval Status')
plt.show()

# Visualize the relationship between Loan_Status and other variables
# For example, you can use sns.countplot() or sns.barplot() for categorical variables,
# and sns.boxplot() or sns.scatterplot() for numerical variables
# Repeat this for other variables you want to explore

# Separate features and target variable
X = loan_df.drop('Loan_Status', axis=1)
y = loan_df['Loan_Status']

# Encode categorical variables cant aplly bcz all cols must be of same datatype str or int
# encoder = LabelEncoder()
# X_encoded = X.apply(encoder.fit_transform)

# Split the dataset into training and test sets (80% train, 20% test)
# X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

expected_columns = X.columns.tolist()

# During prediction (Streamlit or elsewhere)
# Ensure input_data has same columns
input_data = X[expected_columns]
print(input_data)

X = loan_df.drop('Loan_ID', axis=1)

X.dtypes

X['Dependents'].dtype

X.dtypes.value_counts()

!pip install pandas

import pandas as pd

non_string_cols = X.select_dtypes(include=["int64", "float64"]).columns.tolist()

for col in non_string_cols:
    X[col] = X[col].astype(str)

X.dtypes

X = X.apply(lambda x: x.astype(str))
# This line converts every column in the DataFrame X into strings â€” regardless of whether the column is numeric or not.



X.dtypes

encoder=LabelEncoder()
X_encoded = X.apply(encoder.fit_transform)

X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

# Use Random Forest Classifier as an example
model = RandomForestClassifier(n_estimators=100, random_state=42)

model.fit(X_train, y_train)

# Predictions on training set
train_preds = model.predict(X_train)
# Predictions on test set
test_preds = model.predict(X_test)

# Calculate accuracy
train_accuracy = accuracy_score(y_train, train_preds)
test_accuracy = accuracy_score(y_test, test_preds)

print("Training Accuracy:", train_accuracy)
print("Test Accuracy:", test_accuracy)

# Confusion matrix for test set
conf_matrix = confusion_matrix(y_test, test_preds)
print("Confusion Matrix:")
print(conf_matrix)

import joblib

# Assuming your model is stored in a variable called `model`
joblib.dump(model, "model6.pkl")

from google.colab import files
files.download("model6.pkl")

# Load and preprocess your data

import pandas as pd
import pickle
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

# Load dataset
loan_df = pd.read_excel("/content/loan-predictionUC.csv (1) (1) (1) (3) (1) (2).xlsx") # Ensure Loan_ID, Loan_Status are present

# Drop ID
loan_df = loan_df.drop('Loan_ID', axis=1)

# Separate features and target
X = loan_df.drop('Loan_Status', axis=1)
y = loan_df['Loan_Status']

# One-hot encode categorical features
X_encoded = pd.get_dummies(X)

# Save the column order for prediction time
with open("x_columns.pkl", "wb") as f:
    pickle.dump(X_encoded.columns.tolist(), f)

# Train model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_encoded, y)

# Save model
with open("loan_model.pkl", "wb") as f:
    pickle.dump(model, f)
from google.colab import files
files.download("loan_model.pkl")
files.download("x_columns.pkl")